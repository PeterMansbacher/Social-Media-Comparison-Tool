{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main_scraper(brand, brand1, brand2, date_range_end, date_range_start):\n",
    "    # Authenticate to Twitter\n",
    "    auth = tweepy.OAuthHandler(\"GLQHotmk7W87lffhzrVvP78Xr\", \"XG7DHRT0H1aTHAaeJr3KujPyQ4CHecaW4vFynMTeD7uQYu7twv\")\n",
    "    auth.set_access_token(\"1069081694982918146-ivPGAPKHcW5iW1aNW02yB0R684i9RI\", \"SKAoOdLNHzDgeIkTaREVzgKb4vZHQ3GQeJGtybPZJ8btZ\")\n",
    "    comments = []\n",
    "    retweets = []\n",
    "    brands = [brand, brand1, brand2]\n",
    "    ##### Standardizing Form Input Dates #####\n",
    "    date_range_end = eval_dates(date_range_end)\n",
    "    date_range_start = eval_dates(date_range_start)\n",
    "    ##### ESTABLISH CONNECTION WITH DB #####\n",
    "    server = \"ls-1ef1825172e62dcc237ee491d09a0c12aff562fe.cn5ycdfnko6g.us-east-1.rds.amazonaws.com\"\n",
    "    database_ = 'smcDB'\n",
    "    username = 'dbmasteruser'\n",
    "    password_ = 'q+o.H1sd$CRRZl&CSl>VK}-(~+t1ea&P'\n",
    "\n",
    "    db = pymysql.connect(host=server, user=username, password=password_, database=database_, charset='utf8mb4',\n",
    "                         cursorclass=pymysql.cursors.DictCursor, port=3306)\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    print(\"Database connection successfully established\")\n",
    "\n",
    "    # Create API object\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    ##### Error catching in case API connection fails #####\n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "    except:\n",
    "        print(\"Error during authentication\")\n",
    "        \n",
    "    ##### Chrome Options #####\n",
    "    chromeOptions = Options()\n",
    "    chromeOptions.add_argument('--no-sandbox')\n",
    "    chromeOptions.add_argument('disable-infobars')\n",
    "    chromeOptions.add_argument('disable-blink-features=AutomationContrlled')\n",
    "    chromeOptions.add_argument('--remote-debugging-port=44224')\n",
    "    chromeOptions.add_argument('--disable-dev-shm-using')\n",
    "    chromeOptions.add_argument('--headless')\n",
    "    chromeOptions.add_argument('disable-setuid-sandbox')\n",
    "    chromeOptions.add_argument('--disable-gpu')\n",
    "    \n",
    "    ##### Begin For-loop which iterates through listed brands #####\n",
    "    for item in brands:\n",
    "        \n",
    "        print(date_range_start)\n",
    "        comments.clear()\n",
    "        retweets.clear()\n",
    "        \n",
    "        ##### Instantiate webdriver #####\n",
    "        driver = webdriver.Chrome()#'C:\\\\Users\\\\slick\\\\Desktop\\\\School Files\\\\Senior Design\\\\Chromedriver\\\\',options=options)\n",
    "        driver.get('https://www.twitter.com/{}'.format(item))\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        ##### Pulling comment and retweet information, due to how they're retrieved - need to stuff the text into lists #####\n",
    "        while True:\n",
    "            comment_element = driver.find_elements_by_xpath(\"//div[@data-testid='reply']\")\n",
    "            retweet_element = driver.find_elements_by_xpath(\"//div[@data-testid='retweet']\")\n",
    "            for comment_count in comment_element:\n",
    "                comments.append(comment_count.text)\n",
    "            for retweet_count in retweet_element:\n",
    "                retweets.append(retweet_count.text)\n",
    "            scroller(driver)\n",
    "            if len(comments) >= 200:\n",
    "                break\n",
    "\n",
    "        ##### Grabbing tweets #####\n",
    "        tweets = api.user_timeline(screen_name=item, count=200, include_rts = True, tweet_mode='extended', exclude_replies=True, exclude='pinned')\n",
    "        ##### Standardizing Tweet Dates #####\n",
    "        eval_dates(tweets)\n",
    "        ##### Synchronizing tweet position with comments/retweets - since those are individually scraped and not API #####\n",
    "        counter = set_counter(tweets, date_range_start)\n",
    "        print(counter)\n",
    "        ##### Tweets are automatically pulled in groups - this removes tweets that fall out of the range #####\n",
    "        remove_extras(tweets, date_range_end, date_range_start)\n",
    "        ##### Removing apostrophes from strings as that's breaking the DB currently (will likely be removed) #####\n",
    "        remove_apostrophe(tweets)\n",
    "\n",
    "        string_to_int(comments)\n",
    "        string_to_int(retweets)\n",
    "\n",
    "        ##### Pushing tweet data to database #####\n",
    "        for tweet in tweets:\n",
    "            print(counter)\n",
    "            print(tweet.created_at, comments[counter], retweets[counter])\n",
    "            rand = random.randint(0, 10000)\n",
    "            sql = '''\n",
    "            insert into smcDB.TWITTER(BrandHandle,PostUrl,PostDate,PostText,Likes,Comments,Retweets) values('%s','%s',\n",
    "            '%s','%s','%i','%i','%i') \n",
    "            ''' % (item, tweet.id, tweet.created_at, tweet.full_text, int(tweet.favorite_count), int(comments[counter]), int(retweets[counter]))\n",
    "            cursor.execute(sql)\n",
    "            db.commit()\n",
    "            counter += 1\n",
    "            print(\"Successfully committed to database\")\n",
    "        tweets.clear()\n",
    "        print(tweets)\n",
    "        driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scroll down the screen and load new elements\n",
    "def scroller(driver):\n",
    "    curr_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, \" + str(curr_height) + \");\")\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if curr_height == new_height:\n",
    "            return curr_height\n",
    "        curr_height = new_height\n",
    "        return curr_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dates(tweets):\n",
    "    # Check if tweets is the list of tweets or the string from user\n",
    "    if isinstance(tweets, tweepy.models.ResultSet):\n",
    "        # Removing time stamp from tweet date and storing into temp\n",
    "        for tweet in tweets:\n",
    "            tweet.created_at = tweet.created_at.date()\n",
    "    # Check if tweets is the list of tweets or the string from user\n",
    "    elif isinstance(tweets, str):\n",
    "            # Parse date into datetime object\n",
    "            temp_str = parse(tweets)\n",
    "            # Remove timestamp from date objects\n",
    "            temp_str = temp_str.date()\n",
    "            return temp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function for testing retrieved information #####\n",
    "def iterate_tweets(tweets, comments, retweets):\n",
    "    counter = 0\n",
    "    for info in tweets:\n",
    "         print(\"ID: {}\".format(info.id))\n",
    "         print(\"Date:\", info.created_at)\n",
    "         print(\"Tweet:\", info.full_text)\n",
    "         print(\"Favorites:\", info.favorite_count)\n",
    "         print(\"Comments: \", comments[counter])\n",
    "         print(\"Retweets: \", retweets[counter])\n",
    "         counter += 1\n",
    "         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function for removing tweets that fall out of range #####\n",
    "def remove_extras(tweets, date_range_end, date_range_start):\n",
    "    for i in reversed(tweets):\n",
    "        if i.created_at < date_range_end or i.created_at > date_range_start:\n",
    "            tweets.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Removing apostrophes from tweet text until DB can handle them #####\n",
    "def remove_apostrophe(tweets):\n",
    "    for item in tweets:\n",
    "        item.full_text = item.full_text.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function to synchronize the comments with the tweet objects, since they're pulled individually #####\n",
    "def set_counter(tweets, date_range_start):\n",
    "    for i in range(len(tweets)):\n",
    "        if tweets[i].created_at > date_range_start:\n",
    "            continue\n",
    "        else:\n",
    "            # Returns the count of the tweet position where the database storage should start\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Function to pass integers to the database instead of ints, for returning views #####\n",
    "##### Function will be modified in semester 2 if possible to include more accurate counts #####\n",
    "def string_to_int(temp):\n",
    "    for item in range(len(temp)):\n",
    "        if len(temp[item]) == 2:\n",
    "            temp[item] = temp[item].replace(\"k\", \"000\")\n",
    "            temp[item] = temp[item].replace(\"K\", \"000\")\n",
    "            temp[item] = temp[item].replace(\".\", \"\")\n",
    "        else:\n",
    "            temp[item] = temp[item].replace(\"k\", \"00\")\n",
    "            temp[item] = temp[item].replace(\"K\", \"00\")\n",
    "            temp[item] = temp[item].replace(\".\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Testing Section #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import getpass\n",
    "import calendar\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "import urllib.request\n",
    "import pymysql\n",
    "import random\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "main_scraper(\"target\", \"walmart\", \"apple\", \"2021-11-15\", \"2021-12-01\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Documentation Section #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Comment and Retweet Count Scraping #####\n",
    "'''\n",
    "1.) Comments and retweets are currently out of sync with the actual tweets themselves. The reason for this is currently \n",
    "being evaluated. When the code is executed, certain tweets are skipped over and it's currently unclear why. As it stands, the\n",
    "code will jump to a tweet well below the current scroll of the website - and then jump back. This error forces the synchronization\n",
    "of tweets and comments/retweets to be off by a few tweets upon each iteration of the program.\n",
    "2.) Currently it's being investigated whether or not tweets are being \"re-scraped\" after they code jumps down and back up. \n",
    "If the tweets are not being re-scraped, we can accept this within the margin of error of the program given that it is\n",
    "around a 5% error rate. However, if it is discovered that tweets are being duplicated, the issue will have to be rectified and\n",
    "the synchronization will have to either account for the discrepancies and remove them, or stop them from happening altogether.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Regarding ReTweets #####\n",
    "'''\n",
    "1.) Please note that retweets return a \"likes\" value of 0 from the API. This is not seen as an issue because the post\n",
    "isn't actually coming from the brand that's being scraped. They've been included due to synchronization efforts of \n",
    "comments/retweets (where here retweets means the number of times a post from the brand was retweeted) with their respective\n",
    "tweets.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
