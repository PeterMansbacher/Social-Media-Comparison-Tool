{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup ##html parsing library\n",
    "import bs4\n",
    "\n",
    " \n",
    "import pandas as pd #dataframe library\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import selenium.webdriver as webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from time import sleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User will enter brand handles one at a time\n",
      "User, enter the name of the first brand and press enter->target\n",
      "User, enter the name of the second brand and press enter->walmart\n",
      "User, enter the name of the third brand and press enter->home depot\n",
      "First search=https://www.instagram.com/target Second search=https://www.instagram.com/walmart Third search=https://www.instagram.com/homedepot\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['https://www.instagram.com/target', ' '],\n",
       " ['https://www.instagram.com/walmart', ' '],\n",
       " ['https://www.instagram.com/homedepot', ' ']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"User will enter brand handles one at a time\")\n",
    "\n",
    "#usrListFile = file.csv\n",
    "\n",
    "#\n",
    "domainName = 'https://www.instagram.com/'#instagram domain url\n",
    "\n",
    "\n",
    "brandHandle1 = input(\"User, enter the name of the first brand and press enter->\")\t\n",
    "brandHandle1=brandHandle1.replace(\" \", \"\")#remove whitespace\n",
    "\n",
    "brandHandle2 = input(\"User, enter the name of the second brand and press enter->\")\t\n",
    "brandHandle2=brandHandle2.replace(\" \", \"\")#remove whitespace\n",
    "\n",
    "brandHandle3 = input(\"User, enter the name of the third brand and press enter->\")\t\n",
    "brandHandle3=brandHandle3.replace(\" \", \"\")#remove whitespace\n",
    "\n",
    "\n",
    "\n",
    "firstSearch = domainName + brandHandle1 #combine brand handle and domain url\n",
    "\n",
    "secondSearch = domainName + brandHandle2#combine brand handle and domain url\n",
    "\n",
    "thirdSearch = domainName + brandHandle3 #combine brand handle and domain url\n",
    "\n",
    "print(\"First search={} Second search={} Third search={}\".format(firstSearch,secondSearch,thirdSearch))\n",
    "\n",
    "print()\n",
    "\n",
    "handlesList=[[firstSearch,' '],[secondSearch, ' '], [thirdSearch,' ']]\n",
    "\n",
    "handlesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"file1.csv\", \"a\")\n",
    "f.write(firstSearch)\n",
    "f.write(\", \\n\")\n",
    "f.write(secondSearch)\n",
    "f.write(\", \\n\")\n",
    "f.write(thirdSearch)\n",
    "f.write(\", \")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"file1.csv\", names=['url','text'], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "brandsList=[brandHandle1,brandHandle2,brandHandle3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make sure url valid\n",
    "\n",
    "def is_valid(url):\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and bool(parsed.scheme)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for urls in df[\"url\"]:\n",
    "   # print(scrape_data(urls))#test if scrape data working with correct values (urls)\n",
    "#    df[\"text\"][urls] = scrape_data(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow0_col1 {\n",
       "            width:  200px;\n",
       "        }    #T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow1_col1 {\n",
       "            width:  200px;\n",
       "        }    #T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow2_col1 {\n",
       "            width:  200px;\n",
       "        }</style><table id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >url</th>        <th class=\"col_heading level0 col1\" >text</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3flevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow0_col0\" class=\"data row0 col0\" >https://www.instagram.com/target</td>\n",
       "                        <td id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow0_col1\" class=\"data row0 col1\" > </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3flevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow1_col0\" class=\"data row1 col0\" >https://www.instagram.com/walmart</td>\n",
       "                        <td id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow1_col1\" class=\"data row1 col1\" > </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3flevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow2_col0\" class=\"data row2 col0\" >https://www.instagram.com/homedepot</td>\n",
       "                        <td id=\"T_2e925b32_2704_11ec_a2e1_9eb6d0dccd3frow2_col1\" class=\"data row2 col1\" > </td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d4c2f88a30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)\n",
    "df.style.set_properties(subset=['text'], **{'width': '200px'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor urls in df[\"url\"]:\\n    headers = {\"user-agent\":\\'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\\'}\\n    page = requests.get(urls, headers=headers);\\n    soup = BeautifulSoup(page.content, \\'html.parser\\');\\n    #print(soup.head.title)\\n    df[\"text\"][urls]= soup.find_all(\"span\",class_=\\'g47SY lOXF2\\')\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for urls in df[\"url\"]:\n",
    "    headers = {\"user-agent\":'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'}\n",
    "    page = requests.get(urls, headers=headers);\n",
    "    soup = BeautifulSoup(page.content, 'html.parser');\n",
    "    #print(soup.head.title)\n",
    "    df[\"text\"][urls]= soup.find_all(\"span\",class_='g47SY lOXF2')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \n",
       "1     \n",
       "2     \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df.to_csv(\"output\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor urls in df[\"url\"]:\\n    page = requests.get(urls, headers=headers);\\n    soup = BeautifulSoup(page.content, \\'html.parser\\');\\n    for x in soup.findAll(\\'span\\', {\\'class\\':\\'g47SY lOXF2\\'}):\\n        print(x)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for urls in df[\"url\"]:\n",
    "    page = requests.get(urls, headers=headers);\n",
    "    soup = BeautifulSoup(page.content, 'html.parser');\n",
    "    for x in soup.findAll('span', {'class':'g47SY lOXF2'}):\n",
    "        print(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor urls in df[\"url\"]:\\n    print(\"url=\",urls)\\n    browser = webdriver.Chrome(executable_path=ChromeDriverManager().install())\\n    browser.get(urls)\\n    for elem in browser.find_elements_by_xpath(\\'.//span[@class = \"gbts\"]\\'):\\n        print (elem.text)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for urls in df[\"url\"]:\n",
    "    print(\"url=\",urls)\n",
    "    browser = webdriver.Chrome(executable_path=ChromeDriverManager().install())\n",
    "    browser.get(urls)\n",
    "    for elem in browser.find_elements_by_xpath('.//span[@class = \"gbts\"]'):\n",
    "        print (elem.text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/94.0.4606.61/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\peter\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61]\n",
      "<ipython-input-15-d6d0b015018c>:25: DeprecationWarning: use options instead of chrome_options\n",
      "  browser = webdriver.Chrome(chrome_options=chrome_options, executable_path=ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram\n",
      "Instagram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [C:\\Users\\peter\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram\n",
      "Instagram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [C:\\Users\\peter\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instagram\n",
      "Instagram\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "#argument to switch off suid sandBox and no sandBox in Chrome \n",
    "chrome_options.add_argument(\"start-maximized\")\n",
    "chrome_options.add_argument(\"disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-setuid-sandbox\")\n",
    "\n",
    "\n",
    "user=\"CSCI4738\"\n",
    "password_=\"Password4738\"\n",
    "\n",
    "for brands in brandsList :\n",
    "    username=brands\n",
    "    browser = webdriver.Chrome(chrome_options=chrome_options, executable_path=ChromeDriverManager().install())\n",
    "    sleep(3)\n",
    "    browser.get('https://www.instagram.com/')\n",
    "    print(browser.title)\n",
    "    sleep(2)\n",
    "    #\"\"\"\n",
    "    username = browser.find_element_by_name('username')#create object to hold username and edit interact with html code\n",
    "    username.clear()#clear username\n",
    "    username.send_keys(user)#set username\n",
    "    password= browser.find_element_by_name('password')#create password obj\n",
    "    password.clear()#clear field\n",
    "    password.send_keys(password_)#send password\n",
    "    submit=browser.find_element_by_tag_name('form')#submit obj \n",
    "    submit.submit()#enter\n",
    "    Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #The following code is from\n",
    "    #https://medium.com/analytics-vidhya/web-scraping-instagram-with-selenium-python-b8e77af32ad4\n",
    "    #save your login info?\n",
    "    sleep(30)\n",
    "    notsaved=browser.find_element_by_class_name(\"yWX7d\")#for not saving password\n",
    "    notsaved.click()\n",
    "    #searchbox\n",
    "    sleep(5)\n",
    "    notnow=browser.find_element_by_class_name(\"HoLwm\")#for not saving password\n",
    "    notnow.click()\n",
    "    sleep(7)\n",
    "    searchbox=browser.find_element_by_css_selector(\"input[placeholder='Search']\")\n",
    "    searchbox.clear()\n",
    "    searchbox.send_keys(brands)#enter brand each iteration\n",
    "    sleep(5)\n",
    "    searchbox.send_keys(Keys.ENTER)\n",
    "    sleep(5)\n",
    "    searchbox.send_keys(Keys.ENTER)\n",
    "    print(browser.title)\n",
    "    #\"\"\"\n",
    "    sleep(3)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-57c3bcc8b1ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'elem' is not defined"
     ]
    }
   ],
   "source": [
    "print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.instagram.com/kongcompany</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/kaytee</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/petsmart</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     url text\n",
       "0  https://www.instagram.com/kongcompany     \n",
       "1       https://www.instagram.com/kaytee     \n",
       "2     https://www.instagram.com/petsmart     "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url):\n",
    "#url = messages[5]\n",
    "\n",
    "#     parsed = urlparse(url)\n",
    "#     # remove URL GET parameters, URL fragments, etc.\n",
    "#     url = parsed.scheme + \"://\" + parsed.netloc + parsed.path\n",
    "\n",
    "#     if not is_valid(url):\n",
    "#         data = \" \"\n",
    "#     else:\n",
    "        response = requests.get(url)\n",
    "        response_page = response.content\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        text = soup.find_all(text=True)\n",
    "        #output = np.empty([])\n",
    "        #output = pd.Series(data=data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        data = []\n",
    "\n",
    "\n",
    "        blacklist = [\n",
    "            '[document]',\n",
    "            'noscript',\n",
    "            'header',\n",
    "            'html',\n",
    "            'meta',\n",
    "            'head', \n",
    "            'input',\n",
    "            'script',\n",
    "            'body',\n",
    "            'menu',\n",
    "            'style',\n",
    "            #'jsx-195647250 header-container white middle',\n",
    "            \n",
    "            # there may be more elements you don't want, such as \"style\", etc.\n",
    "        ]\n",
    "        \n",
    "        whitelist=[\n",
    "            'jsx-1473136130 share-layout-header share-header',\n",
    "            'number'\n",
    "            \n",
    "        ]\n",
    "\n",
    "        for t in text:\n",
    "            if (t.parent.name not in blacklist) or (t.parent.name in whitelist):\n",
    "                data += '{}'.format(t)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        #print(\"NOT APPENDED LIST\")\n",
    "        #print(output)\n",
    "        data = \"\".join(data)\n",
    "        \n",
    "        print(\"APPENDED LIST\\n\")\n",
    "        #print(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
