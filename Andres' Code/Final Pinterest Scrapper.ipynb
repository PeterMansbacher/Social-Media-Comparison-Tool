{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf562b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final driver program\n",
    "# * Final Version * \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import copy\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import urllib.request\n",
    "import pymysql\n",
    "import datetime\n",
    "\n",
    "\n",
    "def datesInput():\n",
    "    userdate = input(\"(YYYY-MM-DD):\")\n",
    "    year, month, day = map(int, userdate.split('-'))\n",
    "    userdate = datetime.date(year, month, day)\n",
    "\n",
    "    return userdate\n",
    "\n",
    "\n",
    "def check_for_div_class_count(html, class_name):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    milspecs = soup.findAll('div', {'class': class_name})\n",
    "    return len(milspecs)\n",
    "\n",
    "def get_date(s):\n",
    "    if s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ B9u zDA IZT swG\"}) == None:\n",
    "        return (\"No Date Found\")\n",
    "    else:\n",
    "#         print(\"Date: \", s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ B9u zDA IZT swG\"}).text)\n",
    "\n",
    "#       Format of date needs to be = \"2019-02-02\"\n",
    "#         return (s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ B9u zDA IZT swG\"}).text)\n",
    "        return(\"0000-00-00\")\n",
    "\n",
    "def get_emojis(s):\n",
    "    # If emojis are not found on a post\n",
    "    if s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ pBj zDA IZT swG\"}) == None:\n",
    "        return 0\n",
    "    else:\n",
    "        # Check if emoji tag that was found contains valid data\n",
    "        emoji_tag = s.findAll(\"div\", {\"class\":\"tBJ dyH iFc yTZ pBj zDA IZT swG\"})[-1].text\n",
    "        # Emoji number has potential to have a 'k' value at the end \n",
    "        if emoji_tag.isnumeric() or emoji_tag[:-1].isnumeric() or isfloat(emoji_tag[:-1]):\n",
    "            if emoji_tag[-1] == 'k':\n",
    "                return (float(emoji_tag[:-1]) * 1000)\n",
    "            else:\n",
    "                return (float(emoji_tag))\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "def get_comments(s, h):\n",
    "    # Check for 2 different types of pages for comments\n",
    "    # New style of comments section\n",
    "    if s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ B9u zDA IZT mWe\"}) != None:\n",
    "        if s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ B9u zDA IZT mWe\"}).text[0].isnumeric():\n",
    "            return(int(s.find(\"div\", {\"class\":\"tBJ dyH iFc yTZ B9u zDA IZT mWe\"}).text.split()[0]))\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # Old style of comments in pinterest\n",
    "    else:\n",
    "        comments = check_for_div_class_count(h, \"VxL zI7 iyn Hsu\")\n",
    "\n",
    "        # Check if any comments exist on page\n",
    "        if comments == None:\n",
    "            return 0\n",
    "        else:\n",
    "            # If more than 2 comments, need to check for more comments\n",
    "            if comments >= 2:\n",
    "                try:\n",
    "                    if s.find(\"div\", {\"class\":\"Hvp zI7 iyn Hsu\"}).text:\n",
    "                        additional_comments = s.find(\"div\", {\"class\":\"Hvp zI7 iyn Hsu\"}).text.split()[0]\n",
    "                        a_c = int(additional_comments)\n",
    "                        comments += int(a_c)\n",
    "                        return comments\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    milspecs = s.findAll('div', {'class': \"VxL zI7 iyn Hsu\"})\n",
    "                    return(len(milspecs))\n",
    "                except:\n",
    "                    return 0\n",
    "            else:\n",
    "                return comments\n",
    "            \n",
    "            \n",
    "def get_image_url(s):\n",
    "    all_imgs = s.find_all('img')\n",
    "    return(all_imgs[1]['src'])\n",
    "\n",
    "\n",
    "def get_pin_description(s):\n",
    "    if s.find(\"div\", {\"class\":\"FNs hDW zI7 iyn Hsu\"}) == None:\n",
    "        return(\"No Description\")\n",
    "    else:\n",
    "        return (s.find(\"div\", {\"class\":\"FNs hDW zI7 iyn Hsu\"}).text)\n",
    "    \n",
    "# Determine if a value is a float  \n",
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Scroll through webpage\n",
    "def scroller():\n",
    "    curr_height = browser.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, \" + str(curr_height) + \");\")\n",
    "        time.sleep(1)\n",
    "        new_height = browser.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if curr_height == new_height:\n",
    "            break\n",
    "        curr_height = new_height\n",
    "\n",
    "def pinterest_scraper(h_list, s_date, e_date):\n",
    "    # Server Settings\n",
    "    chromeOptions = Options()\n",
    "    chromeOptions.add_argument('--no-sandbox')\n",
    "    chromeOptions.add_argument('--remote-debugging-port=44224')\n",
    "    chromeOptions.add_argument('--disable-dev-shm-using')\n",
    "    chromeOptions.add_argument('--headless')\n",
    "    chromeOptions.add_argument('disable-setuid-sandbox')\n",
    "    chromeOptions.add_argument('disable-gpu')\n",
    "    \n",
    "    delta = s_date - e_date\n",
    "    \n",
    "    # Conditional statements to determine how many pins are going to be scraped\n",
    "    if abs(delta.days) <= 30:\n",
    "        pin_amount = 20\n",
    "    elif abs(delta.days) > 30 and abs(delta.days) < 90:\n",
    "        pin_amount = 50\n",
    "    elif abs(delta.days) >= 90:\n",
    "        pin_amount = 100\n",
    "    \n",
    "    \n",
    "    # Need to download chrome driver and place in python code path in order to work\n",
    "    browser = webdriver.Chrome(executable_path=ChromeDriverManager().install(), options=chromeOptions)\n",
    "    \n",
    "    # ESTABLISH CONNECTION WITH DB\n",
    "    server = \"ls-1ef1825172e62dcc237ee491d09a0c12aff562fe.cn5ycdfnko6g.us-east-1.rds.amazonaws.com\"\n",
    "    database_ = 'smcDB'\n",
    "    username = 'dbmasteruser'\n",
    "    password_ = 'q+o.H1sd$CRRZl&CSl>VK}-(~+t1ea&P'\n",
    "\n",
    "    db = pymysql.connect(host=server, user=username, password=password_, database=database_, charset='utf8mb4',\n",
    "                         cursorclass=pymysql.cursors.DictCursor, port=3306)\n",
    "    cursor = db.cursor()\n",
    "\n",
    "#     print(\"Database connection successfully established\")\n",
    "    \n",
    "    # Log in information for pinterest account\n",
    "    usernameStr = 'andres.dicochea@ucdenver.edu'\n",
    "    passwordStr = 'SchoolRocks16'\n",
    "\n",
    "    # Go to pinterest log in page\n",
    "    browser.get(\"https://pinterest.com/login\")\n",
    "    sleep(5)\n",
    "\n",
    "    # Enter fields to log in\n",
    "    username_field = browser.find_element_by_id('email')\n",
    "    username_field.clear()\n",
    "    username_field.send_keys(usernameStr)\n",
    "    password_field = browser.find_element_by_id('password')\n",
    "    password_field.clear()\n",
    "    password_field.send_keys(passwordStr)\n",
    "    submit=browser.find_element_by_tag_name('form')\n",
    "    submit.submit() # log into pinterest\n",
    "    sleep(5)\n",
    "    \n",
    "    total_dates_found = 0\n",
    "    total_emojis_found = 0\n",
    "    total_comments_found = 0\n",
    "\n",
    "    # Go each brands account's and get pins\n",
    "    for handle in h_list:\n",
    "        total_handle_comments = 0\n",
    "        total_handle_dates = 0\n",
    "        total_handle_emojis = 0\n",
    "        \n",
    "        browser.get(\"https://pinterest.com/\" + handle + \"/pins/\")\n",
    "        sleep(5)\n",
    "        \n",
    "        # Get page page source for brand handle\n",
    "        page_source = browser.page_source\n",
    "        page = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        all_pin_links = []\n",
    "        previous_pin_amount = 0\n",
    "        while 1:\n",
    "            # get the html of the webpage\n",
    "            page_source = browser.page_source\n",
    "            page = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Store all pins that are found on current view of the webpage\n",
    "            productLinks = [div.a for div in \n",
    "                page.findAll('div', attrs={'class' : 'Yl- MIw Hb7'})]\n",
    "\n",
    "            # Convert all product links into https links\n",
    "            for index,link in enumerate(productLinks):\n",
    "                productLinks[index] = \"https://pinterest.com\" + link['href']\n",
    "\n",
    "            # Append to overall list of pin links\n",
    "            all_pin_links.extend(productLinks)\n",
    "\n",
    "            # Remove duplicates in the list\n",
    "            temp_list = []\n",
    "            [temp_list.append(x) for x in all_pin_links if x not in temp_list]\n",
    "            all_pin_links = copy.deepcopy(temp_list)\n",
    "\n",
    "            # Break out of loop once enough pins have been gathered\n",
    "            if len(all_pin_links) >= int(pin_amount) or previous_pin_amount == len(all_pin_links):\n",
    "                break\n",
    "\n",
    "            # Scroll through webpage to get pin list\n",
    "            browser.execute_script(\"window.scrollBy(0,10000)\")\n",
    "            time.sleep(3)\n",
    "            browser.execute_script(\"window.scrollBy(0,10000)\")\n",
    "            time.sleep(3)\n",
    "\n",
    "            # Save previous amount of pins to avoid infinite loop\n",
    "            previous_pin_amount = len(all_pin_links)\n",
    "\n",
    "        # Cut off extra pins in pin list\n",
    "        del all_pin_links[int(pin_amount):]\n",
    "\n",
    "        for link in all_pin_links:\n",
    "            sleep(10)\n",
    "            browser.get(link)\n",
    "            print (link)\n",
    "\n",
    "            sleep(10)\n",
    "            html = browser.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "\n",
    "            # Find date of post\n",
    "            date = str(get_date(soup))\n",
    "\n",
    "            # Find total emojis on page\n",
    "            emojis = str(get_emojis(soup))\n",
    "\n",
    "            # Find total amount of comments\n",
    "            comments = str(get_comments(soup, html))\n",
    "            \n",
    "            # Get image for pin\n",
    "            image_url = str(get_image_url(soup))\n",
    "            \n",
    "            # Get description for pin\n",
    "            description = str(get_pin_description(soup))\n",
    "            description = description.replace(\"'\",\"\")\n",
    "            \n",
    "            shares = \"0\"\n",
    "            pins = \"0\"\n",
    "            closeups = \"0\"\n",
    "            saves = \"0\"\n",
    "\n",
    "            \n",
    "            sql = '''\n",
    "            insert into smcDB.PINTEREST(BrandHandle,PostUrl,PostDate,PostText,Emoticons,Comments,Shares,Pins,Closeups,Saves,ImageUrl) values('%s','%s',\n",
    "            '%s','%s','%s','%s','%s','%s','%s','%s','%s') \n",
    "            ''' % (handle, link, date, description, emojis, comments, shares, pins, closeups, saves, image_url)\n",
    "            cursor.execute(sql)\n",
    "            db.commit()\n",
    "\n",
    "            print(\"Successfully committed to database\")\n",
    "    \n",
    "    \n",
    "# Get input handle from user\n",
    "handle_list = []\n",
    "handle_list.append(input(\"Input account name: \"))\n",
    "handle_list.append(input(\"Input account name: \"))\n",
    "handle_list.append(input(\"Input account name: \"))\n",
    "handle_list.append(input(\"Input account name: \"))\n",
    "handle_list.append(input(\"Input account name: \"))\n",
    "\n",
    "# userdate = datesInput()\n",
    "# userdate1 = datesInput()\n",
    "\n",
    "\n",
    "# Run scraper\n",
    "pinterest_scraper(handle_list, start_date, end_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
